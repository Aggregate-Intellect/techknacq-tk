#!/usr/bin/env python3

import sys
import time

from flask import Flask, request, jsonify
from flask_cors import CORS

from t.conceptgraph import ConceptGraph
from t.readinglist import ReadingList

app = Flask(__name__)
CORS(app)

# This has fewer limitations than `timeit`.
def timed(f):
    start = time.time()
    ret = f()
    elapsed = time.time() - start
    return ret, elapsed

@app.route('/readingList', methods=['GET'])
def handle_request():
    try:
        q = request.args.get('query')
        # We ignore the `d` and `t` parameters specifying the number of
        # documents or dependent topics to return, for now.
    except:
        return {'Error': 'Bad request.'}

    print('Generating reading list for', q + ':', end=' ')
    r, elapsed = timed(lambda: ReadingList(cg, q.strip().split()))
    print('%.4f seconds.' % (elapsed))

    def topic_entry(topic):
        nonlocal doc_index, resp

        node = {'id': topic['id'],
                'label': topic['name'],
                'matched': False}
        resp['graphResponse']['nodes'].append(node)

        entry = {'index': topic['id'],
                 'topicName': topic['name'],
                 'dependentTopics': [],
                 'documents': []}
        for doc in topic['documents1']:
            entry['documents'].append(doc_entry(doc))
            doc_index += 1
        for subtopic in topic['subconcepts']:
            entry['dependentTopics'].append(topic_entry(subtopic))
        for doc in topic['documents2']:
            entry['documents'].append(doc_entry(doc))
            doc_index += 1
        return entry

    def doc_entry(doc):
        nonlocal doc_index
        return {'index': doc_index,
                'id': doc['id'],
                'author': '; '.join(doc['authors']),
                'authorScore': 0.0,
                'title': doc['title'],
                'year': doc['year'],
                'relevanceScore': 0.0,
                'readabilityScore': 0.0,
                'pageRankScore': 0.0,
                'pedagogicalRole': None,
                'relevantTopics': [],
                'url': doc['url'],
                'abstractText': ' '.join(doc['abstract'])}

    resp = {'keyword': q,
            'baseLineDocuments': [],
            'graphResponse': {
              'edges': [],
              'nodes': []},
            'matchTopics': []}

    doc_index = 0
    for topic in r.rl:
        resp['matchTopics'].append(topic_entry(topic))
    # Add dependency edges to the graph in the response for all topic nodes
    # we added.
    topics = set([x['id'] for x in resp['graphResponse']['nodes']])
    for topic in topics:
        for dep_id, dep_weight in cg.topic_deps(topic):
            if dep_id in topics:
                edge = {'from': topic,
                        'to': dep_id,
                        'value': dep_weight}
                resp['graphResponse']['edges'].append(edge)

    #r.print()

    return jsonify(resp)


if __name__ == '__main__':
    if len(sys.argv) < 2:
        sys.stderr.write('Usage: server [concept graph]\n')
        sys.exit(1)

    print('Reading concept graph:', end=' ')
    cg = ConceptGraph(sys.argv[1])
    print('done.')

    app.run(debug=True, host='colo-vm17.isi.edu', port=9898)
