#!/usr/bin/env python3

# Score each topic in a Mallet topic model file based on cosine similarity
# in a Word2Vec model.
# Jonathan Gordon, 2016-03-01

import sys
import os
import argparse
import re
import numpy
import itertools
import random

from math import sqrt
from gensim import matutils
from gensim.models.word2vec import Word2Vec
from nltk.stem.wordnet import WordNetLemmatizer


def cosine_similarity(u, v):
    return numpy.dot(matutils.unitvec(u), matutils.unitvec(v))


class TopicModel:
    # A list of (word, weight) pairs for each topic.
    topic_words = []

    def read_unweighted(self, fname):
        for line in open(fname, 'r').readlines():
            self.topic_words.append([])
            line = line.strip().replace('#', '')
            tokens = re.split('[ \t]', line)[2:]
            for word in tokens:
                self.topic_words[-1].append((word, 1))

    def read_weighted(self, fname):
        for line in open(fname, 'r').readlines():
            self.topic_words.append([])
            line = line.strip().replace('#', '')
            tokens = re.split('[ \t]', line)[1:]
            total = sum([float(x) for x in tokens[1::2]])
            for (word, weight) in zip(tokens[::2], tokens[1::2]):
                self.topic_words[-1].append((word, float(weight)/total))


class Evaluation:
    def __init__(self):
        self.lmtzr = WordNetLemmatizer()

    def read_word2vec(self, fname):
        self.model = Word2Vec.load_word2vec_format(fname, binary=True)

    def read_word2vec_linhong(self, words_file, vectors_file):
        # Put Linhong's files into the Word2vec text format to be read by
        # gensim.
        all_words = open(words_file).readlines()
        all_vectors = open(vectors_file).readlines()
        with open('tmp.txt', 'w') as out:
            print(len(all_words), len(all_vectors[0].split()), file=out)
            for (word, vector) in zip(all_words, all_vectors):
                print(word.strip().replace(' ', '_'),
                      vector.strip().replace('\t', ' '),
                      file=out)
        self.model = Word2Vec.load_word2vec_format('tmp.txt', binary=False)
        os.remove('tmp.txt')


    def get_words(self, word, fuzzy=False):
        if word in self.model:
            return [word]

        word = re.sub("[-']", '_', word)
        if word in self.model:
            return [word]

        if fuzzy and self.lmtzr.lemmatize(word) in self.model:
            return [self.lmtzr.lemmatize(word)]

        ret = []
        for w in word.split('_'):
            if w in self.model:
                ret.append(w)
                continue
            if not fuzzy:
                continue
            combine = []
            if self.lmtzr.lemmatize(w) in self.model:
                combine.append(self.lmtzr.lemmatize(w))
            if w + 's' in self.model:
                combine.append(w + 's')
            if w + 'es' in self.model:
                combine.append(w + 'es')
            if self.lmtzr.lemmatize(w) + 's' in self.model:
                combine.append(self.lmtzr.lemmatize(w) + 's')
            if self.lmtzr.lemmatize(w) + 'es' in self.model:
                combine.append(self.lmtzr.lemmatize(w) + 'es')
            if w + 'ed' in self.model:
                combine.append(w + 'ed')
            if w + 'ing' in self.model:
                combine.append(w + 'ing')
            if self.lmtzr.lemmatize(w) + 'ed' in self.model:
                combine.append(self.lmtzr.lemmatize(w) + 'ed')
            if self.lmtzr.lemmatize(w) + 'ing' in self.model:
                combine.append(self.lmtzr.lemmatize(w) + 'ing')
            if combine:
                ret.append(combine)
        return ret


    def word2vec(self, words):
        def avg_vectors(vectors):
            result = vectors[0]
            for vector in vectors[1:]:
                for i in range(0, len(result)):
                    result[i] += vector[i]
            for i in range(0, len(result)):
                result[i] /= len(vectors)
            return result
        res = []
        for word in words:
            # It's a sublist containing alternatives, e.g.,
            #   ['models', 'modeling', 'modeled']
            # when 'model' is not in the Word2vec model.
            if isinstance(word, list):
                comb = []
                for w in word:
                    try:
                        comb.append(self.model[w])
                    except:
                        pass
                if comb:
                    res.append(avg_vectors(comb))
                continue
            try:
                res.append(self.model[word])
            except:
                pass
        res = avg_vectors(res)
        return res


    def run(self, topic_model, weighted=False, fuzzy=False):
        weight = 1
        total_average = 0.0

        for topic in topic_model.topic_words:
            avgscore = 0.0
            for pair1, pair2 in itertools.product(topic, repeat=2):
                if pair1 is pair2:
                    continue

                if weighted:
                    weight = pair1[1] * pair2[1]

                words1 = self.get_words(pair1[0], fuzzy)
                if words1:
                    l1 = self.word2vec(words1)
                else:
                    continue

                words2 = self.get_words(pair2[0], fuzzy)
                if words2:
                    l2 = self.word2vec(words2)
                else:
                    continue

                avgscore += cosine_similarity(l1, l2) * weight

            avgscore /= (len(topic) * len(topic))
            print(avgscore)
            total_average += avgscore

        total_average /= len(topic_model.topic_words)
#        print('Average', total_average)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Score a topic model.')
    parser.add_argument('-w', dest='weighted', action='store_true')
    parser.add_argument('-f', dest='fuzzy', action='store_true')
    parser.add_argument('topic_model', type=argparse.FileType('r'))
    args = parser.parse_args()

    e = Evaluation()
    #e.read_word2vec_linhong('News+ACL-words.txt', 'News+ACL-word2vec-20.txt')
    e.read_word2vec('/Users/jgordon/Models/News-300.bin')

    topic_model = TopicModel()
    if args.weighted:
        topic_model.read_weighted(sys.argv[1])
    else:
        topic_model.read_unweighted(sys.argv[1])

    e.run(topic_model, args.weighted, args.fuzzy)
