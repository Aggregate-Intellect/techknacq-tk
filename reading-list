#!/usr/bin/env python3

import sys

from collections import defaultdict

from t.conceptgraph import ConceptGraph


# Parameters

THRESHOLD = 0.02
MAX_MATCHES = 6


# User model constants

BEGINNER = 1
INTERMEDIATE = 2
ADVANCED = 3


class ReadingList:
    def __init__(self, cg, query, user_model):
        self.query = set(query)
        self.cg = cg
        self.user_model = user_model
        self.covered = set()
        self.relevance = dict([(c, self.score_match(c))
                               for c in cg.concepts()])

        for c, score in sorted(self.relevance.items(), key=lambda x: x[1],
                               reverse=True)[:MAX_MATCHES]:
            self.traverse(c, score)


    def traverse(self, c, score, depth=1):
        if score < THRESHOLD or c in self.covered:
            return

        if depth == MAX_MATCHES:
            return

        self.covered.add(c)

        print('  '*depth + '%s -- %.4f' % (self.cg.name(c), score))

        for dep, dep_weight in self.cg.topic_deps(c)[:MAX_MATCHES]:
            self.traverse(dep, score * dep_weight + self.relevance[dep],
                          depth+1)


    def score_match(self, c):
        """Score the relevance of a concept to a query based on lexical
        overlap."""

        mentions = self.cg.g.node[c]['mentions']
        score = 0.0
        for word, weight in self.cg.g.node[c]['words']:
            # Each match is scored as the % of distinct words the query
            # and the feature share * weight of the feature in the topic, e.g.,
            # - Query: 'knowledge'
            #   Topic feature: ('knowledge_base', 323)
            #   Return: (1/2) * (323 / topic_mentions)
            # - Query: 'knowledge base generation'
            #   Topic feature: ('data base', 323)
            #   Return: (1/4) * (323 / topic_mentions)
            words = set(word.split('_'))
            all_words = self.query | words
            common = self.query & words
            score += (len(common)/len(all_words)) * (weight/mentions)
        return score



####


# def score_concept(cg, query, c, visited=set()):
#     s = score_match(cg, query, c)
#     if c in visited:
#         return s
#     visited.add(c)
#     for d, d_score in cg.topic_deps(c):
#         if d_score > 0.1:
#             # Using 'set' to pass a copy instead of a pointer.
#             s += d_score * score_concept(cg, query, d, set(visited))
#     return s


# def topic_reading_list(cg, concept_id, concept_weight, depth=0):
#     """Print a reading list for the topic and its dependencies."""

#     global covered

#     # Have we previously covered this topic, e.g., it was a dependency of
#     # an earlier topic?
#     if concept_id in covered:
#         return

#     # If we've passed the threshold of relevance, don't continue.
#     if concept_weight < 0.01:
#         return

#     print(' ' * depth + ' - %s (%s) %.4f' %
#           (cg.g.node[concept_id]['name'], concept_id, concept_weight))
#     covered.add(concept_id)

#     for dep, weight in cg.topic_deps(concept_id):
#         topic_reading_list(cg, dep, concept_weight * weight, depth+1)


if __name__ == '__main__':
    if len(sys.argv) < 3:
        sys.stderr.write('Usage: reading-list [concept graph] [query terms]\n')
        sys.exit(1)

    cg = ConceptGraph(sys.argv[1])

    query = sys.argv[2:]

    beginner_model = {}
    for c in cg.concepts():
        beginner_model[c] = BEGINNER

    r = ReadingList(cg, query, beginner_model)
