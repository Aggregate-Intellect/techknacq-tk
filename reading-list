#!/usr/bin/env python3

import sys

from collections import defaultdict

from t.conceptgraph import ConceptGraph


# Parameters

THRESHOLD = 0.02
MAX_MATCHES = 6


# User model constants

BEGINNER = 1
INTERMEDIATE = 2
ADVANCED = 3


class ReadingList:
    def __init__(self, cg, query, user_model):
        self.query = set(query)
        self.cg = cg
        self.user_model = user_model
        self.covered = set()
        self.relevance = dict([(c, self.score_match(c))
                               for c in cg.concepts()])
        self.rl = []

        for c, score in sorted(self.relevance.items(), key=lambda x: x[1],
                               reverse=True)[:MAX_MATCHES]:
            entry = self.traverse(c, score)
            if entry:
                self.rl.append(entry)

        self.print(self.rl)


    def traverse(self, c, score, depth=1):
        if score < THRESHOLD or c in self.covered:
            return

        if depth == MAX_MATCHES:
            return

        self.covered.add(c)

        entry = {'id': c,
                 'name': self.cg.name(c),
                 'score': score,
                 'documents1': [],
                 'subconcepts': [],
                 'documents2': []}

        # First compute any dependencies we'll include in the reading list
        # so we know which documents we want to include at this level.
        for dep, dep_weight in self.cg.topic_deps(c)[:MAX_MATCHES]:
            dep_entry = self.traverse(dep, score*dep_weight +
                                      self.relevance[dep], depth+1)
            if dep_entry:
                entry['subconcepts'].append(dep_entry)

        # Documents to print before the dependencies.
        doc_id, doc_weight = self.cg.topic_docs(c)[0]
        entry['documents1'].append(
            {'id': doc_id,
             'score': doc_weight,
             'type': 'unknown',
             'title': self.cg.g.node[doc_id]['title'],
             'authors': self.cg.g.node[doc_id]['authors'],
             'book': self.cg.g.node[doc_id]['book'],
             'year': self.cg.g.node[doc_id]['year']})

        # Documents to print after the dependencies, if there were any.
        if entry['subconcepts']:
            # Bookend dependencies.
            doc_id, doc_weight = self.cg.topic_docs(c)[1]
            entry['documents2'].append(
                {'id': doc_id,
                 'score': doc_weight,
                 'type': 'unknown',
                 'title': self.cg.g.node[doc_id]['title'],
                 'authors': self.cg.g.node[doc_id]['authors'],
                 'book': self.cg.g.node[doc_id]['book'],
                 'year': self.cg.g.node[doc_id]['year']})

        return entry


    def print(self, rl, depth=1):
        for entry in rl:
            print()
            print('  '*depth + '%s -- %.4f' % (entry['name'], entry['score']))

            for doc in entry['documents1']:
                self.print_doc(doc['id'], depth)

            self.print(entry['subconcepts'], depth + 1)

            for doc in entry['documents2']:
                self.print_doc(doc['id'], depth)
        print()


    def print_doc(self, doc_id, depth):
        if len(self.cg.g.node[doc_id]['authors']) > 3:
            print('  '*depth + '- ' +
                  self.cg.g.node[doc_id]['authors'][0] + ' et al.:')
        elif self.cg.g.node[doc_id]['authors']:
            print('  '*depth + '- ' +
                  '; '.join(self.cg.g.node[doc_id]['authors']) + ':')
        else:
            print('  '*depth + '- Unknown:')

        if len(self.cg.g.node[doc_id]['title']) > 70:
            print('  '*depth + '  ' + self.cg.g.node[doc_id]['title'][:70] +
                  '...')
        else:
            print('  '*depth + '  ' + self.cg.g.node[doc_id]['title'])


    def score_match(self, c):
        """Score the relevance of a concept to a query based on lexical
        overlap."""

        mentions = self.cg.g.node[c]['mentions']
        score = 0.0
        for word, weight in self.cg.g.node[c]['words']:
            # Each match is scored as the % of distinct words the query
            # and the feature share * weight of the feature in the topic, e.g.,
            # - Query: 'knowledge'
            #   Topic feature: ('knowledge_base', 323)
            #   Return: (1/2) * (323 / topic_mentions)
            # - Query: 'knowledge base generation'
            #   Topic feature: ('data base', 323)
            #   Return: (1/4) * (323 / topic_mentions)
            words = set(word.split('_'))
            all_words = self.query | words
            common = self.query & words
            score += (len(common)/len(all_words)) * (weight/mentions)
        return score


if __name__ == '__main__':
    if len(sys.argv) < 3:
        sys.stderr.write('Usage: reading-list [concept graph] [query terms]\n')
        sys.exit(1)

    cg = ConceptGraph(sys.argv[1])

    query = sys.argv[2:]

    beginner_model = {}
    for c in cg.concepts():
        beginner_model[c] = BEGINNER

    r = ReadingList(cg, query, beginner_model)
